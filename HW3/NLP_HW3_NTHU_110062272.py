# -*- coding: utf-8 -*-
"""main.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1viMXN3lxb2OCiqqeP-9gmdfadS279_Wd
"""

from transformers import BertTokenizer, BertModel

!pip install evaluate
!pip install datasets==2.21.0 --break-system-packages
from datasets import load_dataset
from evaluate import load
import torch
from torch.utils.data import Dataset, DataLoader
from torch.optim import AdamW
from tqdm import tqdm
device = "cuda" if torch.cuda.is_available() else "cpu"
#  You can install and import any other libraries if needed
import os

# Some Chinese punctuations will be tokenized as [UNK], so we replace them with English ones
token_replacement = [
    ["：" , ":"],
    ["，" , ","],
    ["“" , "\""],
    ["”" , "\""],
    ["？" , "?"],
    ["……" , "..."],
    ["！" , "!"]
]

tokenizer = BertTokenizer.from_pretrained("google-bert/bert-base-uncased", cache_dir="./cache/")

class SemevalDataset(Dataset):
    def __init__(self, split="train") -> None:
        super().__init__()
        assert split in ["train", "validation", "test"]
        self.data = load_dataset(
            "sem_eval_2014_task_1", split=split, trust_remote_code=True, cache_dir="./cache/"
        ).to_list()

    def __getitem__(self, index):
        d = self.data[index]
        # Replace Chinese punctuations with English ones
        for k in ["premise", "hypothesis"]:
            for tok in token_replacement:
                d[k] = d[k].replace(tok[0], tok[1])
        return d

    def __len__(self):
        return len(self.data)

data_sample = SemevalDataset(split="train").data[:3]
print(f"Dataset example: \n{data_sample[0]} \n{data_sample[1]} \n{data_sample[2]}")

# Define the hyperparameters
# You can modify these values if needed
lr = 3e-5
epochs = 3
train_batch_size = 8
validation_batch_size = 8

# TODO1: Create batched data for DataLoader
# `collate_fn` is a function that defines how the data batch should be packed.
# This function will be called in the DataLoader to pack the data batch.

def collate_fn(batch):
    # TODO1-1: Implement the collate_fn function
    # Write your code here
    # The input parameter is a data batch (tuple), and this function packs it into tensors.
    # Use tokenizer to pack tokenize and pack the data and its corresponding labels.
    # Return the data batch and labels for each sub-task.
    premises = [item['premise'] for item in batch]
    hypotheses = [item['hypothesis'] for item in batch]

    relatedness_scores = torch.tensor([item['relatedness_score'] for item in batch], dtype=torch.float)
    entailment_judgements = torch.tensor([item['entailment_judgment'] for item in batch], dtype=torch.long)
    encoded = tokenizer(
        premises,
        hypotheses,
        padding=True,
        truncation=True,
        max_length=128,
        return_tensors='pt'
    )
    return encoded, relatedness_scores, entailment_judgements

# TODO1-2: Define your DataLoader
dl_train = DataLoader(
    SemevalDataset(split="train"),
    batch_size=train_batch_size,
    shuffle=True,
    collate_fn=collate_fn
)
dl_validation = DataLoader(
    SemevalDataset(split="validation"),
    batch_size=validation_batch_size,
    shuffle=False,
    collate_fn=collate_fn
)
dl_test = DataLoader(
    SemevalDataset(split="test"),
    batch_size=validation_batch_size,
    shuffle=False,
    collate_fn=collate_fn
)

# TODO2: Construct your model
class MultiLabelModel(torch.nn.Module):
    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
        # Write your code here
        # Define what modules you will use in the model
        # Please use "google-bert/bert-base-uncased" model (https://huggingface.co/google-bert/bert-base-uncased)
        # Besides the base model, you may design additional architectures by incorporating linear layers, activation functions, or other neural components.
        # Remark: The use of any additional pretrained language models is not permitted.
        self.bert = BertModel.from_pretrained(
            "google-bert/bert-base-uncased",
            cache_dir="./cache/"
        )
        self.regression_head = torch.nn.Linear(768, 1)
        self.classification_head = torch.nn.Linear(768, 3)
        self.dropout = torch.nn.Dropout(0.1)
    def forward(self, **kwargs):
        # Write your code here
        # Forward pass
        outputs = self.bert(
            input_ids=input_ids,
            attention_mask=attention_mask,
            token_type_ids=token_type_ids
        )

        pooled_output = outputs.pooler_output
        pooled_output = self.dropout(pooled_output)

        regression_output = self.regression_head(pooled_output).squeeze(-1)
        classification_output = self.classification_head(pooled_output)
        return regression_output, classification_output

# TODO3: Define your optimizer and loss function

model = MultiLabelModel().to(device)
# TODO3-1: Define your Optimizer
optimizer = AdamW(model.parameters(), lr=lr)

# TODO3-2: Define your loss functions (you should have two)
# Write your code here
regression_loss_fn = torch.nn.MSELoss()
classification_loss_fn = torch.nn.CrossEntropyLoss()

# scoring functions
psr = load("pearsonr")
acc = load("accuracy")

best_score = 0.0
os.makedirs('./saved_models', exist_ok=True)
for ep in range(epochs):
    # ========== Training Loop ==========
    pbar = tqdm(dl_train)
    pbar.set_description(f"Training epoch [{ep+1}/{epochs}]")
    model.train()

    # TODO4: Write the training loop
    for batch in pbar:
        encoded, relatedness_labels, entailment_labels = batch
        input_ids = encoded['input_ids'].to(device)
        attention_mask = encoded['attention_mask'].to(device)
        token_type_ids = encoded['token_type_ids'].to(device)
        relatedness_labels = relatedness_labels.to(device)
        entailment_labels = entailment_labels.to(device)

        # clear gradient
        optimizer.zero_grad()

        # forward pass
        regression_output, classification_output = model(
            input_ids=input_ids,
            attention_mask=attention_mask,
            token_type_ids=token_type_ids
        )
        loss_regression = regression_loss_fn(regression_output, relatedness_labels)
        loss_classification = classification_loss_fn(classification_output, entailment_labels)
        total_loss = loss_regression + loss_classification
        total_loss.backward()
        optimizer.step()

        pbar.set_postfix({'loss': total_loss.item()})

    # ========== Validation Loop ==========
    pbar = tqdm(dl_validation)
    pbar.set_description(f"Validation epoch [{ep+1}/{epochs}]")
    model.eval()

    # TODO5: Write the evaluation loop
    # Write your code here
    # Evaluate your model
    # Output all the evaluation scores (PearsonCorr, Accuracy)

    all_regression_preds = []
    all_regression_labels = []
    all_classification_preds = []
    all_classification_labels = []

    with torch.no_grad():
        for batch in pbar:
            encoded, relatedness_labels, entailment_labels = batch

            input_ids = encoded['input_ids'].to(device)
            attention_mask = encoded['attention_mask'].to(device)
            token_type_ids = encoded['token_type_ids'].to(device)

            regression_output, classification_output = model(
                input_ids=input_ids,
                attention_mask=attention_mask,
                token_type_ids=token_type_ids
            )

            all_regression_preds.extend(regression_output.cpu().numpy())
            all_regression_labels.extend(relatedness_labels.numpy())
            classification_preds = torch.argmax(classification_output, dim=1)
            all_classification_preds.extend(classification_preds.cpu().numpy())
            all_classification_labels.extend(entailment_labels.numpy())

    pearson_corr = psr.compute(
        predictions=all_regression_preds,
        references=all_regression_labels
    )['pearsonr']

    accuracy = acc.compute(
        predictions=all_classification_preds,
        references=all_classification_labels
    )['accuracy']

    # print(f"F1 Score: {f1.compute()}")

    if pearson_corr + accuracy > best_score:
        best_score = pearson_corr + accuracy
        torch.save(model.state_dict(), f'./saved_models/best_model.ckpt')

# Load the model
model = MultiLabelModel().to(device)
model.load_state_dict(torch.load(f"./saved_models/best_model.ckpt", weights_only=True))

# Test Loop
pbar = tqdm(dl_test, desc="Test")
model.eval()

# TODO6: Write the test loop
# Write your code here
# We have loaded the best model with the highest evaluation score for you
# Please implement the test loop to evaluate the model on the test dataset
# We will have 10% of the total score for the test accuracy and pearson correlation
all_regression_preds = []
all_regression_labels = []
all_classification_preds = []
all_classification_labels = []

with torch.no_grad():
    for batch in pbar:
        encoded, relatedness_labels, entailment_labels = batch
        input_ids = encoded['input_ids'].to(device)
        attention_mask = encoded['attention_mask'].to(device)
        token_type_ids = encoded['token_type_ids'].to(device)

        # Forward pass
        regression_output, classification_output = model(
            input_ids=input_ids,
            attention_mask=attention_mask,
            token_type_ids=token_type_ids
        )

        all_regression_preds.extend(regression_output.cpu().numpy())
        all_regression_labels.extend(relatedness_labels.numpy())

        classification_preds = torch.argmax(classification_output, dim=1)
        all_classification_preds.extend(classification_preds.cpu().numpy())
        all_classification_labels.extend(entailment_labels.numpy())

test_pearson_corr = psr.compute(
    predictions=all_regression_preds,
    references=all_regression_labels
)['pearsonr']

test_accuracy = acc.compute(
    predictions=all_classification_preds,
    references=all_classification_labels
)['accuracy']

print(f"Test Pearson Correlation: {test_pearson_corr:.4f}")
print(f"Test Accuracy: {test_accuracy:.4f}")